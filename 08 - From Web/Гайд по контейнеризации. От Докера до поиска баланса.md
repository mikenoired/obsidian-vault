---
День: 2025-09-09
url: https://chatgpt.com/c/68bfd06d-ad08-8324-a3f9-a77006cce6f2
tags:
  - "#Web"
---
Контейнеризация давно перестала быть «новой игрушкой» для инженеров. Сегодня Docker и его экосистема — это неотъемлемая часть индустрии, такой же базис, как Git или CI/CD. Но у многих специалистов остаётся ощущение, что контейнеры — это что-то громоздкое, чрезмерно сложное и не всегда нужное. На самом деле, всё упирается в то, **как и где использовать контейнеризацию**, и где провести ту самую линию баланса между удобством и сложностью.

Попробуем пройти путь от простых команд до стратегических решений.

---

## Зачем вообще нужны контейнеры?

Прежде чем запускать `docker run hello-world`, нужно понять проблему, которую они решают.  
Классический сценарий: разработчик запускает приложение у себя локально, всё работает. Он отдаёт код коллеге — и внезапно у того рушится половина зависимостей. У продакшн-сервера версия Node.js одна, у тестового окружения — другая, у разработчиков — третья. Зависимости конфликтуют, инфраструктура становится хрупкой.

Контейнеры дают иллюзию (а по факту — практическую реальность) изоляции:

- **Одинаковое окружение везде.** Что запустилось у тебя на MacBook, запустится на Linux-сервере.
- **Минимальная стоимость миграции.** Контейнер можно поднять где угодно — хоть на сервере в гараже, хоть в облаке.
- **Простота масштабирования.** Нужно ещё один инстанс? Запускаешь ещё один контейнер.

---

## Первое знакомство: Docker в командной строке

Начнём с базовых примеров.

1. Проверка, что Docker установлен и работает:

```bash
docker --version
docker info
```

2. Запуск тестового контейнера:

```bash
docker run hello-world
```

Эта команда скачает минимальный образ из Docker Hub и запустит его. Если вы видите сообщение «Hello from Docker!», значит контейнеризация на вашей машине заработала.

3. Запуск контейнера с Nginx:

```bash
docker run -d -p 8080:80 nginx
```

- `-d` — запустить в фоне.
- `-p 8080:80` — проброс порта с 8080 вашей машины на 80-й внутри контейнера.
- `nginx` — имя образа.

Теперь можно открыть `http://localhost:8080` и увидеть работающий Nginx.

---

## Dockerfile: ваш рецепт окружения

Контейнеризация без `Dockerfile` — это как разработка без Git: можно, но неудобно.

Простейший пример для Node.js:

```dockerfile
# Базовый образ
FROM node:18

# Рабочая директория
WORKDIR /app

# Копируем зависимости
COPY package*.json ./
RUN npm install

# Копируем весь проект
COPY . .

# Запускаем
CMD ["npm", "start"]
```

Сборка и запуск:

```bash
docker build -t my-app .
docker run -p 3000:3000 my-app
```

Что это решает? Теперь твой коллега не будет спрашивать «А у тебя какая версия Node?», всё уже зашито в образ.

---

## Docker Compose: когда контейнеров становится несколько

Реальные проекты редко ограничиваются одним процессом. Условный «pet-project» часто состоит из:

- приложения на Node.js или Python,
- базы данных (Postgres, свой Supabase),
- кэша (Redis),
- иногда ещё брокера сообщений (Kafka, RabbitMQ).

Запускать всё вручную — боль. Здесь помогает **Docker Compose**.

Пример `docker-compose.yml`:

```yaml
version: "3.8"
services:
  app:
    build: .
    ports:
      - "3000:3000"
    depends_on:
      - db

  db:
    image: postgres:15
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
      POSTGRES_DB: mydb
    volumes:
      - pgdata:/var/lib/postgresql/data

volumes:
  pgdata:
```

Запуск одной командой:

```bash
docker compose up -d
```

Теперь у вас и приложение, и база стартуют синхронно, с предсказуемыми настройками.

---

## Контейнеризация в команде: как это работает на практике

**Сценарий 1. Onboarding нового разработчика.**  
Вместо README на 3 страницы с «Сначала установи Postgres, потом Redis, потом вот эту версию Node» вы даёте команду:

```bash
docker compose up
```

и через минуту у человека готовое окружение.

**Сценарий 2. CI/CD.**  
При деплое вы можете собирать образы и выкатывать их на сервер. Никаких «а почему у нас на staging не работает». Всё одинаково.

**Сценарий 3. Эксперименты.**  
Хотите протестировать приложение с другой версией базы? Подменили строку в Compose, запустили. Без риска сломать глобальную систему.

---

## Обратная сторона контейнеризации

Звучит слишком хорошо, правда? У контейнеров есть и минусы:

1. **Накладные расходы.**  
    Да, Docker лёгкий по сравнению с виртуальными машинами, но всё же он потребляет ресурсы. На слабых машинах это чувствуется.
2. **Сложность экосистемы.**  
    Когда проект растёт, одного Docker Compose мало. Появляется Kubernetes, Helm, мониторинг, ingress-контроллеры — и внезапно вы тонете в океане YAML.
3. **Не всегда оправдано.**  
    Для маленьких скриптов или одноразовых pet-проектов контейнеризация может быть лишней. Иногда проще поставить Postgres локально.

---
## Баланс: где контейнеризация оправдана, а где нет

Контейнеризация — инструмент. Как и любой инструмент, её сила в том, **где и как её применяют**.

- **Оправдано:**
    - командные проекты, где важна единообразная среда;
    - CI/CD пайплайны;
    - тестирование и staging окружения;
    - микросервисные архитектуры.
- **Не всегда нужно:**
    - быстрые pet-проекты;
    - скрипты, которые запускаются раз в месяц;
    - приложения, завязанные на тяжёлые десктопные GUI.

---
## Kubernetes: когда Docker Compose перестаёт хватать

Docker Compose решает массу проблем на локальной машине или в небольших командах. Но в какой-то момент вы начинаете упираться в потолок:
- сервисов становится десятки;
- нужно масштабировать приложение под нагрузку;
- появляются разные окружения: dev, staging, prod;
- нужна отказоустойчивость и автоматическое восстановление при сбое.

И тут в игру вступает Kubernetes (K8s).

---
### Что такое Kubernetes простыми словами?

Если Docker — это «контейнеризация одного приложения», а Docker Compose — «оркестрация нескольких приложений на одной машине», то Kubernetes — это «оркестрация на кластере машин».

Он отвечает за:
- автоматический запуск и перезапуск контейнеров;
- балансировку нагрузки;
- хранение конфигураций и секретов;
- масштабирование «по кнопке» или автоматически;
- централизованный контроль над всем парком сервисов.

---
### Первый контакт: Minikube

Чтобы познакомиться с Kubernetes, не нужно сразу арендовать десяток серверов. Достаточно поставить **Minikube** — локальный кластер «в миниатюре».

Установка (Linux/macOS):

```bash
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube
```

Запуск:

```bash
minikube start
```

Проверка состояния:

```bash
kubectl get nodes
```

Если видим `Ready`, значит локальный кластер работает.

---
### Первые манифесты: Deployment и Service

Простейший пример приложения в Kubernetes — **Deployment**.

Создадим файл `app-deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app
        image: nginx
        ports:
        - containerPort: 80
```

Применяем:

```bash
kubectl apply -f app-deployment.yaml
```

Теперь у нас работает 2 реплики Nginx.

Чтобы получить доступ снаружи, нужен **Service** (`app-service.yaml`):

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app-service
spec:
  type: NodePort
  selector:
    app: my-app
  ports:
    - port: 80
      targetPort: 80
      nodePort: 30001
```

Применяем:

```bash
kubectl apply -f app-service.yaml
```

Теперь приложение доступно на `http://localhost:30001`.

---
### Балансировка и отказоустойчивость

Допустим, одна из реплик Nginx упала. Kubernetes автоматически поднимет её снова. Именно это делает его ценным: не нужно руками перезапускать контейнеры или следить за каждым процессом.

Если нагрузка растёт, можно масштабировать:

```bash
kubectl scale deployment my-app --replicas=5
```

И теперь у вас уже 5 реплик, обслуживающих трафик.

---
### Когда Kubernetes действительно нужен

- **Микросервисы.** Когда приложение разбито на десятки сервисов.
- **Продакшн с высокой доступностью.** Если простой в 5 минут стоит денег.
- **Динамическая нагрузка.** Когда ночью у вас 100 пользователей, а днём — 10 000.
- **Командная разработка и DevOps.** K8s позволяет всем говорить на одном «языке инфраструктуры».

---
### Когда Kubernetes — это overkill

- **Маленький стартап или pet-проект.** Поднимать кластер ради ToDo-приложения — лишнее.
- **Монолитное приложение.** Если у вас одно API и одна база — Docker Compose закрывает все задачи.
- **Ограниченные ресурсы.** Kubernetes требует серьёзного железа и знаний.

---
### Kubernetes vs Docker Compose: аналогия

Представим ресторан:
- **Docker** — это когда у каждого повара своя плита.
- **Docker Compose** — это маленькая кухня, где плиты объединены, и всё готовится синхронно.
- **Kubernetes** — это сеть ресторанов, где есть менеджер, распределяющий заказы, контролирующий закупки и нанимающий новых поваров, если пришёл автобус туристов.

---
### Баланс в использовании Kubernetes

K8s не всегда должен быть «дефолтом».
- В команде из 3 человек, делающих MVP, Kubernetes чаще мешает, чем помогает.
- Но в крупной компании с десятками сервисов он становится спасением.

Главное — помнить: **Kubernetes — это про автоматизацию управления хаосом.** Если хаоса нет, вам не нужен тяжёлый оркестратор.

## CI/CD и Kubernetes: деплой на практике

Контейнеризация решает проблему «у меня работает — у тебя нет». Kubernetes решает проблему «у меня работает на staging, а в проде всё горит». Но самое важное — это связка с CI/CD. Автоматический деплой избавляет от ручных костылей и делает доставку кода предсказуемой.

---
### Основная идея пайплайна

1. **Собираем Docker-образ** приложения.
2. **Отправляем образ** в реестр (Docker Hub, GitHub Container Registry, GitLab, ECR/GCR).
3. **Применяем манифесты в Kubernetes** (или Helm-чарты).
4. (Опционально) **Роллинг-деплой**: обновляем по одной реплике, без даунтайма.

---
### Пример: GitHub Actions + Kubernetes

Представим, что у нас есть приложение с `Dockerfile` и Kubernetes-манифестами в папке `k8s/`.

`.github/workflows/deploy.yml`:

```yaml
name: Deploy to Kubernetes

on:
  push:
    branches:
      - main

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Log in to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build and push Docker image
        run: |
          docker build -t myuser/myapp:${{ github.sha }} .
          docker push myuser/myapp:${{ github.sha }}

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Configure kubeconfig
        run: |
          echo "${{ secrets.KUBECONFIG }}" > $HOME/.kube/config

      - name: Deploy to Kubernetes
        run: |
          kubectl set image deployment/my-app my-app=myuser/myapp:${{ github.sha }}
```

Что здесь происходит:
- при пуше в `main` собирается образ;
- он пушится в Docker Hub;
- `kubectl` подключается к кластеру;
- деплой обновляется на новый образ.

---
### Пример: GitLab CI/CD + Kubernetes

В GitLab всё аналогично, только используется встроенный `kubernetes` executor.

`.gitlab-ci.yml`:

```yaml
stages:
  - build
  - deploy

build:
  stage: build
  script:
    - docker build -t registry.gitlab.com/myuser/myapp:$CI_COMMIT_SHA .
    - docker push registry.gitlab.com/myuser/myapp:$CI_COMMIT_SHA

deploy:
  stage: deploy
  script:
    - kubectl set image deployment/my-app my-app=registry.gitlab.com/myuser/myapp:$CI_COMMIT_SHA
  environment:
    name: production
  only:
    - main
```

---
### Helm: деплой «по-взрослому»

Kubernetes YAML-манифесты быстро превращаются в «кладбище файлов». Тут на сцену выходит **Helm** — пакетный менеджер для K8s.

Пример `values.yaml` для приложения:

```yaml
replicaCount: 3

image:
  repository: myuser/myapp
  tag: "latest"

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: true
  className: nginx
  hosts:
    - host: myapp.example.com
      paths:
        - path: /
          pathType: Prefix
```

Деплой через GitHub Actions:

```bash
helm upgrade --install my-app ./chart -f values.yaml
```

Helm решает проблему «копипасты» и делает деплой управляемым: можно настраивать параметры через `values.yaml` для разных окружений.

---
### Роллинг-деплой и zero-downtime

По умолчанию Kubernetes использует стратегию **RollingUpdate**: обновляет по одной реплике, пока весь деплой не перейдёт на новый образ.

Проверить:

```bash
kubectl rollout status deployment my-app
```

Откатиться, если что-то пошло не так:

```bash
kubectl rollout undo deployment my-app
```

---

### Где здесь баланс?

- Если у вас **маленький проект**, можно обойтись GitHub Actions → Docker Hub → `ssh` на сервер и `docker-compose pull && docker-compose up -d`.
- Если у вас **средний проект**, Kubernetes + GitHub Actions/GitLab CI без Helm — уже хорошо.
- Если у вас **большой проект с множеством сервисов**, Helm + CI/CD + мониторинг становятся must-have.